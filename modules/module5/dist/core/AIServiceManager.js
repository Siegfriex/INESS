"use strict";
/**
 * AI Service Manager
 * ë‹¤ì–‘í•œ AI ì„œë¹„ìŠ¤ë“¤ì„ í†µí•© ê´€ë¦¬í•˜ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸
 */
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.AIServiceManager = void 0;
const openai_1 = __importDefault(require("openai"));
const sdk_1 = __importDefault(require("@anthropic-ai/sdk"));
const logger_1 = require("../utils/logger");
class AIServiceManager {
    constructor(config) {
        this.isInitialized = false;
        this.config = config || this.loadConfigFromEnv();
        logger_1.aiLogger.info('ğŸ¤– AIServiceManager ìƒì„±ë¨');
    }
    /**
     * í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
     */
    loadConfigFromEnv() {
        return {
            openai: process.env.OPENAI_API_KEY ? {
                apiKey: process.env.OPENAI_API_KEY,
                model: process.env.OPENAI_MODEL || 'gpt-4',
                maxTokens: parseInt(process.env.OPENAI_MAX_TOKENS || '4096')
            } : undefined,
            anthropic: process.env.ANTHROPIC_API_KEY ? {
                apiKey: process.env.ANTHROPIC_API_KEY,
                model: process.env.ANTHROPIC_MODEL || 'claude-3-sonnet-20240229',
                maxTokens: parseInt(process.env.ANTHROPIC_MAX_TOKENS || '4096')
            } : undefined,
            google: process.env.GOOGLE_AI_API_KEY ? {
                apiKey: process.env.GOOGLE_AI_API_KEY,
                model: process.env.GOOGLE_AI_MODEL || 'gemini-pro'
            } : undefined
        };
    }
    /**
     * AI ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™”
     */
    async initialize() {
        try {
            logger_1.aiLogger.info('ğŸ”„ AI ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™” ì¤‘...');
            // OpenAI ì´ˆê¸°í™”
            if (this.config.openai) {
                this.openaiClient = new openai_1.default({
                    apiKey: this.config.openai.apiKey
                });
                logger_1.aiLogger.info('âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
            }
            // Anthropic ì´ˆê¸°í™”
            if (this.config.anthropic) {
                this.anthropicClient = new sdk_1.default({
                    apiKey: this.config.anthropic.apiKey
                });
                logger_1.aiLogger.info('âœ… Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
            }
            // Google AI ì´ˆê¸°í™” (í–¥í›„ êµ¬í˜„)
            if (this.config.google) {
                // TODO: Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                logger_1.aiLogger.info('ğŸ“‹ Google AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜ˆì •');
            }
            this.isInitialized = true;
            logger_1.aiLogger.info('âœ… ëª¨ë“  AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ');
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
            throw new Error(`AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error}`);
        }
    }
    /**
     * OpenAI í…ìŠ¤íŠ¸ ìƒì„±
     */
    async generateWithOpenAI(prompt, options) {
        const startTime = Date.now();
        try {
            if (!this.openaiClient) {
                throw new Error('OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            }
            const messages = [];
            if (options?.systemPrompt) {
                messages.push({
                    role: 'system',
                    content: options.systemPrompt
                });
            }
            messages.push({
                role: 'user',
                content: prompt
            });
            const completion = await this.openaiClient.chat.completions.create({
                model: options?.model || this.config.openai.model || 'gpt-4',
                messages,
                max_tokens: options?.maxTokens || this.config.openai.maxTokens || 4096,
                temperature: options?.temperature || 0.7
            });
            const responseTime = Date.now() - startTime;
            const response = {
                content: completion.choices[0]?.message?.content || '',
                model: completion.model,
                provider: 'openai',
                tokensUsed: completion.usage?.total_tokens || 0,
                responseTime,
                timestamp: new Date().toISOString()
            };
            logger_1.aiLogger.info('âœ… OpenAI ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
                model: response.model,
                tokensUsed: response.tokensUsed,
                responseTime: `${responseTime}ms`
            });
            return response;
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ OpenAI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);
            throw new Error(`OpenAI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: ${error}`);
        }
    }
    /**
     * Anthropic í…ìŠ¤íŠ¸ ìƒì„±
     */
    async generateWithAnthropic(prompt, options) {
        const startTime = Date.now();
        try {
            if (!this.anthropicClient) {
                throw new Error('Anthropic í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            }
            const message = await this.anthropicClient.messages.create({
                model: options?.model || this.config.anthropic.model || 'claude-3-sonnet-20240229',
                max_tokens: options?.maxTokens || this.config.anthropic.maxTokens || 4096,
                temperature: options?.temperature || 0.7,
                system: options?.systemPrompt,
                messages: [
                    {
                        role: 'user',
                        content: prompt
                    }
                ]
            });
            const responseTime = Date.now() - startTime;
            const content = message.content[0];
            const response = {
                content: content.type === 'text' ? content.text : '',
                model: message.model,
                provider: 'anthropic',
                tokensUsed: message.usage.input_tokens + message.usage.output_tokens,
                responseTime,
                timestamp: new Date().toISOString()
            };
            logger_1.aiLogger.info('âœ… Anthropic ì‘ë‹µ ìƒì„± ì™„ë£Œ', {
                model: response.model,
                tokensUsed: response.tokensUsed,
                responseTime: `${responseTime}ms`
            });
            return response;
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ Anthropic ì‘ë‹µ ìƒì„± ì‹¤íŒ¨:', error);
            throw new Error(`Anthropic ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: ${error}`);
        }
    }
    /**
     * ìµœì  AI ì„œë¹„ìŠ¤ ìë™ ì„ íƒ ë° ìƒì„±
     */
    async generateSmart(prompt, options) {
        try {
            // ì‘ì—… ìœ í˜•ë³„ ìµœì  í”„ë¡œë°”ì´ë” ì„ íƒ
            let provider = options?.preferredProvider;
            if (!provider) {
                switch (options?.taskType) {
                    case 'creative':
                        provider = this.anthropicClient ? 'anthropic' : 'openai';
                        break;
                    case 'analytical':
                        provider = this.openaiClient ? 'openai' : 'anthropic';
                        break;
                    case 'coding':
                        provider = this.openaiClient ? 'openai' : 'anthropic';
                        break;
                    default:
                        provider = this.openaiClient ? 'openai' : 'anthropic';
                }
            }
            // ì„ íƒëœ í”„ë¡œë°”ì´ë”ë¡œ ìƒì„±
            switch (provider) {
                case 'openai':
                    if (this.openaiClient) {
                        return await this.generateWithOpenAI(prompt, options);
                    }
                    break;
                case 'anthropic':
                    if (this.anthropicClient) {
                        return await this.generateWithAnthropic(prompt, options);
                    }
                    break;
                case 'google':
                    // TODO: Google AI êµ¬í˜„
                    throw new Error('Google AIëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            }
            // í´ë°±: ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ì„œë¹„ìŠ¤ ì‚¬ìš©
            if (this.openaiClient) {
                return await this.generateWithOpenAI(prompt, options);
            }
            else if (this.anthropicClient) {
                return await this.generateWithAnthropic(prompt, options);
            }
            throw new Error('ì‚¬ìš© ê°€ëŠ¥í•œ AI ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤');
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ ìŠ¤ë§ˆíŠ¸ AI ìƒì„± ì‹¤íŒ¨:', error);
            throw error;
        }
    }
    /**
     * ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
     */
    async getServiceStatus() {
        const status = {
            openai: false,
            anthropic: false,
            google: false,
            lastChecked: new Date().toISOString()
        };
        try {
            // OpenAI ìƒíƒœ í™•ì¸
            if (this.openaiClient) {
                try {
                    await this.openaiClient.models.list();
                    status.openai = true;
                }
                catch (error) {
                    logger_1.aiLogger.warn('âš ï¸ OpenAI ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
                }
            }
            // Anthropic ìƒíƒœ í™•ì¸
            if (this.anthropicClient) {
                // Anthropicì€ ì§ì ‘ì ì¸ ìƒíƒœ í™•ì¸ APIê°€ ì—†ìœ¼ë¯€ë¡œ ì´ˆê¸°í™” ìƒíƒœë¡œ íŒë‹¨
                status.anthropic = true;
            }
            // Google AI ìƒíƒœ í™•ì¸ (í–¥í›„ êµ¬í˜„)
            status.google = false;
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜:', error);
        }
        return status;
    }
    /**
     * í—¬ìŠ¤ ì²´í¬
     */
    async healthCheck() {
        try {
            const status = await this.getServiceStatus();
            return status.openai || status.anthropic || status.google;
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ AI ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨:', error);
            return false;
        }
    }
    /**
     * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
     */
    async cleanup() {
        try {
            logger_1.aiLogger.info('ğŸ§¹ AI ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...');
            // í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            this.openaiClient = undefined;
            this.anthropicClient = undefined;
            this.isInitialized = false;
            logger_1.aiLogger.info('âœ… AI ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ');
        }
        catch (error) {
            logger_1.aiLogger.error('âŒ AI ì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨:', error);
            throw error;
        }
    }
}
exports.AIServiceManager = AIServiceManager;
//# sourceMappingURL=AIServiceManager.js.map